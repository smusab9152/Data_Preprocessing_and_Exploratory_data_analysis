{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "ryYkQqqBlGFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (Wine Quality dataset from UCI Repository)\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=';')\n",
        "\n"
      ],
      "metadata": {
        "id": "2JvxieWnlb7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X = df.drop(columns=['quality'])\n",
        "y = df['quality']\n",
        "\n"
      ],
      "metadata": {
        "id": "bjuyuMzZlfUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert target into binary classification (Good vs. Bad wine)\n",
        "y_class = y.apply(lambda x: 1 if x >= 6 else 0)\n",
        "\n",
        "# Split the dataset for classification\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "8QkkXswwlkki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification models\n",
        "classification_models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Ridge Classifier': RidgeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
        "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(kernel='rbf', probability=True),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "iVx8qQ16lroL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classification_model = None\n",
        "best_classification_accuracy = 0\n",
        "\n",
        "# Iterate over classification models and evaluate\n",
        "print(\"\\nClassification Models Evaluation\")\n",
        "for name, model in classification_models.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train_c, y_train_c)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_c = pipeline.predict(X_test_c)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    accuracy = accuracy_score(y_test_c, y_pred_c)\n",
        "    report = classification_report(y_test_c, y_pred_c)\n",
        "\n",
        "    print(f\"\\n{name} Classification Performance:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    if accuracy > best_classification_accuracy:\n",
        "        best_classification_accuracy = accuracy\n",
        "        best_classification_model = name\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx7f-7Vllrqo",
        "outputId": "f27c97d6-9964-4231-ac25-9a50a35c6a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Models Evaluation\n",
            "\n",
            "Logistic Regression Classification Performance:\n",
            "Accuracy: 0.7406\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.74      0.72       141\n",
            "           1       0.79      0.74      0.76       179\n",
            "\n",
            "    accuracy                           0.74       320\n",
            "   macro avg       0.74      0.74      0.74       320\n",
            "weighted avg       0.74      0.74      0.74       320\n",
            "\n",
            "\n",
            "Ridge Classifier Classification Performance:\n",
            "Accuracy: 0.7500\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.77      0.73       141\n",
            "           1       0.80      0.74      0.77       179\n",
            "\n",
            "    accuracy                           0.75       320\n",
            "   macro avg       0.75      0.75      0.75       320\n",
            "weighted avg       0.75      0.75      0.75       320\n",
            "\n",
            "\n",
            "Random Forest Classification Performance:\n",
            "Accuracy: 0.7844\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.75      0.75       141\n",
            "           1       0.81      0.81      0.81       179\n",
            "\n",
            "    accuracy                           0.78       320\n",
            "   macro avg       0.78      0.78      0.78       320\n",
            "weighted avg       0.78      0.78      0.78       320\n",
            "\n",
            "\n",
            "Gradient Boosting Classification Performance:\n",
            "Accuracy: 0.7625\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.77      0.74       141\n",
            "           1       0.81      0.75      0.78       179\n",
            "\n",
            "    accuracy                           0.76       320\n",
            "   macro avg       0.76      0.76      0.76       320\n",
            "weighted avg       0.77      0.76      0.76       320\n",
            "\n",
            "\n",
            "AdaBoost Classification Performance:\n",
            "Accuracy: 0.7312\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70       141\n",
            "           1       0.76      0.76      0.76       179\n",
            "\n",
            "    accuracy                           0.73       320\n",
            "   macro avg       0.73      0.73      0.73       320\n",
            "weighted avg       0.73      0.73      0.73       320\n",
            "\n",
            "\n",
            "Extra Trees Classification Performance:\n",
            "Accuracy: 0.8000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.77      0.77       141\n",
            "           1       0.82      0.83      0.82       179\n",
            "\n",
            "    accuracy                           0.80       320\n",
            "   macro avg       0.80      0.80      0.80       320\n",
            "weighted avg       0.80      0.80      0.80       320\n",
            "\n",
            "\n",
            "SVM Classification Performance:\n",
            "Accuracy: 0.7719\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.77      0.75       141\n",
            "           1       0.81      0.77      0.79       179\n",
            "\n",
            "    accuracy                           0.77       320\n",
            "   macro avg       0.77      0.77      0.77       320\n",
            "weighted avg       0.77      0.77      0.77       320\n",
            "\n",
            "\n",
            "K-Nearest Neighbors Classification Performance:\n",
            "Accuracy: 0.7063\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.62      0.65       141\n",
            "           1       0.72      0.78      0.75       179\n",
            "\n",
            "    accuracy                           0.71       320\n",
            "   macro avg       0.70      0.70      0.70       320\n",
            "weighted avg       0.70      0.71      0.70       320\n",
            "\n",
            "\n",
            "Decision Tree Classification Performance:\n",
            "Accuracy: 0.7344\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.72      0.70       141\n",
            "           1       0.77      0.75      0.76       179\n",
            "\n",
            "    accuracy                           0.73       320\n",
            "   macro avg       0.73      0.73      0.73       320\n",
            "weighted avg       0.74      0.73      0.73       320\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset for regression\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Regression models\n",
        "regression_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting Regressor': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'AdaBoost Regressor': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "    'Extra Trees Regressor': ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "hxChPHLRlrtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_regression_model = None\n",
        "best_r2_score = -float(\"inf\")\n",
        "\n",
        "# Iterate over regression models and evaluate\n",
        "print(\"\\nRegression Models Evaluation\")\n",
        "for name, model in regression_models.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train_r, y_train_r)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_r = pipeline.predict(X_test_r)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    mae = mean_absolute_error(y_test_r, y_pred_r)\n",
        "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
        "    r2 = r2_score(y_test_r, y_pred_r)\n",
        "\n",
        "    print(f\"\\n{name} Regression Performance:\")\n",
        "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "    print(f\"R^2 Score: {r2:.4f}\")\n",
        "\n",
        "    if r2 > best_r2_score:\n",
        "        best_r2_score = r2\n",
        "        best_regression_model = name\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgXFPA7xnUq4",
        "outputId": "8e7e7307-abda-4ff5-c3e9-2e9aa722e7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Regression Models Evaluation\n",
            "\n",
            "Linear Regression Regression Performance:\n",
            "Mean Absolute Error: 0.5035\n",
            "Mean Squared Error: 0.3900\n",
            "R^2 Score: 0.4032\n",
            "\n",
            "Ridge Regression Regression Performance:\n",
            "Mean Absolute Error: 0.5036\n",
            "Mean Squared Error: 0.3900\n",
            "R^2 Score: 0.4032\n",
            "\n",
            "Random Forest Regressor Regression Performance:\n",
            "Mean Absolute Error: 0.4220\n",
            "Mean Squared Error: 0.3007\n",
            "R^2 Score: 0.5399\n",
            "\n",
            "Gradient Boosting Regressor Regression Performance:\n",
            "Mean Absolute Error: 0.4849\n",
            "Mean Squared Error: 0.3623\n",
            "R^2 Score: 0.4456\n",
            "\n",
            "AdaBoost Regressor Regression Performance:\n",
            "Mean Absolute Error: 0.5099\n",
            "Mean Squared Error: 0.3865\n",
            "R^2 Score: 0.4086\n",
            "\n",
            "Extra Trees Regressor Regression Performance:\n",
            "Mean Absolute Error: 0.3892\n",
            "Mean Squared Error: 0.2926\n",
            "R^2 Score: 0.5522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion\n",
        "print(\"\\nConclusion:\")\n",
        "print(f\"The best classification model is {best_classification_model} with an accuracy of {best_classification_accuracy:.4f}.\")\n",
        "print(f\"The best regression model is {best_regression_model} with an R^2 score of {best_r2_score:.4f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pvEZCpHnayG",
        "outputId": "162f8567-7827-450d-c92f-65719e79d853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conclusion:\n",
            "The best classification model is Extra Trees with an accuracy of 0.8000.\n",
            "The best regression model is Extra Trees Regressor with an R^2 score of 0.5522.\n"
          ]
        }
      ]
    }
  ]
}